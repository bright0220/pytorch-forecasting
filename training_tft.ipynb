{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:03.227928Z",
     "start_time": "2020-03-12T22:46:02.122752Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyunpack\n",
    "import math\n",
    "import json\n",
    "\n",
    "from data.data_download import Config, download_electricity\n",
    "from data_formatters.electricity import ElectricityFormatter\n",
    "from data_formatters.base import DataTypes, InputTypes\n",
    "\n",
    "from data.custom_dataset import TFTDataset\n",
    "from models import GatedLinearUnit\n",
    "from models import GateAddNormNetwork\n",
    "from models import GatedResidualNetwork \n",
    "from models import ScaledDotProductAttention\n",
    "from models import InterpretableMultiHeadAttention\n",
    "from models import VariableSelectionNetwork\n",
    "\n",
    "from quantile_loss import QuantileLossCalculator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T16:47:54.934322Z",
     "start_time": "2020-03-09T16:47:54.932271Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config('data','data/electricity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T16:52:20.011881Z",
     "start_time": "2020-03-09T16:47:57.762444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data from https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip to data/LD2011_2014.txt.zip\n",
      "done\n",
      "Unzipping file: data/LD2011_2014.txt.zip\n",
      "Done.\n",
      "Aggregating to hourly data\n",
      "Processing MT_001\n",
      "Processing MT_002\n",
      "Processing MT_003\n",
      "Processing MT_004\n",
      "Processing MT_005\n",
      "Processing MT_006\n",
      "Processing MT_007\n",
      "Processing MT_008\n",
      "Processing MT_009\n",
      "Processing MT_010\n",
      "Processing MT_011\n",
      "Processing MT_012\n",
      "Processing MT_013\n",
      "Processing MT_014\n",
      "Processing MT_015\n",
      "Processing MT_016\n",
      "Processing MT_017\n",
      "Processing MT_018\n",
      "Processing MT_019\n",
      "Processing MT_020\n",
      "Processing MT_021\n",
      "Processing MT_022\n",
      "Processing MT_023\n",
      "Processing MT_024\n",
      "Processing MT_025\n",
      "Processing MT_026\n",
      "Processing MT_027\n",
      "Processing MT_028\n",
      "Processing MT_029\n",
      "Processing MT_030\n",
      "Processing MT_031\n",
      "Processing MT_032\n",
      "Processing MT_033\n",
      "Processing MT_034\n",
      "Processing MT_035\n",
      "Processing MT_036\n",
      "Processing MT_037\n",
      "Processing MT_038\n",
      "Processing MT_039\n",
      "Processing MT_040\n",
      "Processing MT_041\n",
      "Processing MT_042\n",
      "Processing MT_043\n",
      "Processing MT_044\n",
      "Processing MT_045\n",
      "Processing MT_046\n",
      "Processing MT_047\n",
      "Processing MT_048\n",
      "Processing MT_049\n",
      "Processing MT_050\n",
      "Processing MT_051\n",
      "Processing MT_052\n",
      "Processing MT_053\n",
      "Processing MT_054\n",
      "Processing MT_055\n",
      "Processing MT_056\n",
      "Processing MT_057\n",
      "Processing MT_058\n",
      "Processing MT_059\n",
      "Processing MT_060\n",
      "Processing MT_061\n",
      "Processing MT_062\n",
      "Processing MT_063\n",
      "Processing MT_064\n",
      "Processing MT_065\n",
      "Processing MT_066\n",
      "Processing MT_067\n",
      "Processing MT_068\n",
      "Processing MT_069\n",
      "Processing MT_070\n",
      "Processing MT_071\n",
      "Processing MT_072\n",
      "Processing MT_073\n",
      "Processing MT_074\n",
      "Processing MT_075\n",
      "Processing MT_076\n",
      "Processing MT_077\n",
      "Processing MT_078\n",
      "Processing MT_079\n",
      "Processing MT_080\n",
      "Processing MT_081\n",
      "Processing MT_082\n",
      "Processing MT_083\n",
      "Processing MT_084\n",
      "Processing MT_085\n",
      "Processing MT_086\n",
      "Processing MT_087\n",
      "Processing MT_088\n",
      "Processing MT_089\n",
      "Processing MT_090\n",
      "Processing MT_091\n",
      "Processing MT_092\n",
      "Processing MT_093\n",
      "Processing MT_094\n",
      "Processing MT_095\n",
      "Processing MT_096\n",
      "Processing MT_097\n",
      "Processing MT_098\n",
      "Processing MT_099\n",
      "Processing MT_100\n",
      "Processing MT_101\n",
      "Processing MT_102\n",
      "Processing MT_103\n",
      "Processing MT_104\n",
      "Processing MT_105\n",
      "Processing MT_106\n",
      "Processing MT_107\n",
      "Processing MT_108\n",
      "Processing MT_109\n",
      "Processing MT_110\n",
      "Processing MT_111\n",
      "Processing MT_112\n",
      "Processing MT_113\n",
      "Processing MT_114\n",
      "Processing MT_115\n",
      "Processing MT_116\n",
      "Processing MT_117\n",
      "Processing MT_118\n",
      "Processing MT_119\n",
      "Processing MT_120\n",
      "Processing MT_121\n",
      "Processing MT_122\n",
      "Processing MT_123\n",
      "Processing MT_124\n",
      "Processing MT_125\n",
      "Processing MT_126\n",
      "Processing MT_127\n",
      "Processing MT_128\n",
      "Processing MT_129\n",
      "Processing MT_130\n",
      "Processing MT_131\n",
      "Processing MT_132\n",
      "Processing MT_133\n",
      "Processing MT_134\n",
      "Processing MT_135\n",
      "Processing MT_136\n",
      "Processing MT_137\n",
      "Processing MT_138\n",
      "Processing MT_139\n",
      "Processing MT_140\n",
      "Processing MT_141\n",
      "Processing MT_142\n",
      "Processing MT_143\n",
      "Processing MT_144\n",
      "Processing MT_145\n",
      "Processing MT_146\n",
      "Processing MT_147\n",
      "Processing MT_148\n",
      "Processing MT_149\n",
      "Processing MT_150\n",
      "Processing MT_151\n",
      "Processing MT_152\n",
      "Processing MT_153\n",
      "Processing MT_154\n",
      "Processing MT_155\n",
      "Processing MT_156\n",
      "Processing MT_157\n",
      "Processing MT_158\n",
      "Processing MT_159\n",
      "Processing MT_160\n",
      "Processing MT_161\n",
      "Processing MT_162\n",
      "Processing MT_163\n",
      "Processing MT_164\n",
      "Processing MT_165\n",
      "Processing MT_166\n",
      "Processing MT_167\n",
      "Processing MT_168\n",
      "Processing MT_169\n",
      "Processing MT_170\n",
      "Processing MT_171\n",
      "Processing MT_172\n",
      "Processing MT_173\n",
      "Processing MT_174\n",
      "Processing MT_175\n",
      "Processing MT_176\n",
      "Processing MT_177\n",
      "Processing MT_178\n",
      "Processing MT_179\n",
      "Processing MT_180\n",
      "Processing MT_181\n",
      "Processing MT_182\n",
      "Processing MT_183\n",
      "Processing MT_184\n",
      "Processing MT_185\n",
      "Processing MT_186\n",
      "Processing MT_187\n",
      "Processing MT_188\n",
      "Processing MT_189\n",
      "Processing MT_190\n",
      "Processing MT_191\n",
      "Processing MT_192\n",
      "Processing MT_193\n",
      "Processing MT_194\n",
      "Processing MT_195\n",
      "Processing MT_196\n",
      "Processing MT_197\n",
      "Processing MT_198\n",
      "Processing MT_199\n",
      "Processing MT_200\n",
      "Processing MT_201\n",
      "Processing MT_202\n",
      "Processing MT_203\n",
      "Processing MT_204\n",
      "Processing MT_205\n",
      "Processing MT_206\n",
      "Processing MT_207\n",
      "Processing MT_208\n",
      "Processing MT_209\n",
      "Processing MT_210\n",
      "Processing MT_211\n",
      "Processing MT_212\n",
      "Processing MT_213\n",
      "Processing MT_214\n",
      "Processing MT_215\n",
      "Processing MT_216\n",
      "Processing MT_217\n",
      "Processing MT_218\n",
      "Processing MT_219\n",
      "Processing MT_220\n",
      "Processing MT_221\n",
      "Processing MT_222\n",
      "Processing MT_223\n",
      "Processing MT_224\n",
      "Processing MT_225\n",
      "Processing MT_226\n",
      "Processing MT_227\n",
      "Processing MT_228\n",
      "Processing MT_229\n",
      "Processing MT_230\n",
      "Processing MT_231\n",
      "Processing MT_232\n",
      "Processing MT_233\n",
      "Processing MT_234\n",
      "Processing MT_235\n",
      "Processing MT_236\n",
      "Processing MT_237\n",
      "Processing MT_238\n",
      "Processing MT_239\n",
      "Processing MT_240\n",
      "Processing MT_241\n",
      "Processing MT_242\n",
      "Processing MT_243\n",
      "Processing MT_244\n",
      "Processing MT_245\n",
      "Processing MT_246\n",
      "Processing MT_247\n",
      "Processing MT_248\n",
      "Processing MT_249\n",
      "Processing MT_250\n",
      "Processing MT_251\n",
      "Processing MT_252\n",
      "Processing MT_253\n",
      "Processing MT_254\n",
      "Processing MT_255\n",
      "Processing MT_256\n",
      "Processing MT_257\n",
      "Processing MT_258\n",
      "Processing MT_259\n",
      "Processing MT_260\n",
      "Processing MT_261\n",
      "Processing MT_262\n",
      "Processing MT_263\n",
      "Processing MT_264\n",
      "Processing MT_265\n",
      "Processing MT_266\n",
      "Processing MT_267\n",
      "Processing MT_268\n",
      "Processing MT_269\n",
      "Processing MT_270\n",
      "Processing MT_271\n",
      "Processing MT_272\n",
      "Processing MT_273\n",
      "Processing MT_274\n",
      "Processing MT_275\n",
      "Processing MT_276\n",
      "Processing MT_277\n",
      "Processing MT_278\n",
      "Processing MT_279\n",
      "Processing MT_280\n",
      "Processing MT_281\n",
      "Processing MT_282\n",
      "Processing MT_283\n",
      "Processing MT_284\n",
      "Processing MT_285\n",
      "Processing MT_286\n",
      "Processing MT_287\n",
      "Processing MT_288\n",
      "Processing MT_289\n",
      "Processing MT_290\n",
      "Processing MT_291\n",
      "Processing MT_292\n",
      "Processing MT_293\n",
      "Processing MT_294\n",
      "Processing MT_295\n",
      "Processing MT_296\n",
      "Processing MT_297\n",
      "Processing MT_298\n",
      "Processing MT_299\n",
      "Processing MT_300\n",
      "Processing MT_301\n",
      "Processing MT_302\n",
      "Processing MT_303\n",
      "Processing MT_304\n",
      "Processing MT_305\n",
      "Processing MT_306\n",
      "Processing MT_307\n",
      "Processing MT_308\n",
      "Processing MT_309\n",
      "Processing MT_310\n",
      "Processing MT_311\n",
      "Processing MT_312\n",
      "Processing MT_313\n",
      "Processing MT_314\n",
      "Processing MT_315\n",
      "Processing MT_316\n",
      "Processing MT_317\n",
      "Processing MT_318\n",
      "Processing MT_319\n",
      "Processing MT_320\n",
      "Processing MT_321\n",
      "Processing MT_322\n",
      "Processing MT_323\n",
      "Processing MT_324\n",
      "Processing MT_325\n",
      "Processing MT_326\n",
      "Processing MT_327\n",
      "Processing MT_328\n",
      "Processing MT_329\n",
      "Processing MT_330\n",
      "Processing MT_331\n",
      "Processing MT_332\n",
      "Processing MT_333\n",
      "Processing MT_334\n",
      "Processing MT_335\n",
      "Processing MT_336\n",
      "Processing MT_337\n",
      "Processing MT_338\n",
      "Processing MT_339\n",
      "Processing MT_340\n",
      "Processing MT_341\n",
      "Processing MT_342\n",
      "Processing MT_343\n",
      "Processing MT_344\n",
      "Processing MT_345\n",
      "Processing MT_346\n",
      "Processing MT_347\n",
      "Processing MT_348\n",
      "Processing MT_349\n",
      "Processing MT_350\n",
      "Processing MT_351\n",
      "Processing MT_352\n",
      "Processing MT_353\n",
      "Processing MT_354\n",
      "Processing MT_355\n",
      "Processing MT_356\n",
      "Processing MT_357\n",
      "Processing MT_358\n",
      "Processing MT_359\n",
      "Processing MT_360\n",
      "Processing MT_361\n",
      "Processing MT_362\n",
      "Processing MT_363\n",
      "Processing MT_364\n",
      "Processing MT_365\n",
      "Processing MT_366\n",
      "Processing MT_367\n",
      "Processing MT_368\n",
      "Processing MT_369\n",
      "Processing MT_370\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "download_electricity(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:11.900173Z",
     "start_time": "2020-03-12T22:46:03.767234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting train-valid-test splits.\n",
      "Setting scalers with training data...\n"
     ]
    }
   ],
   "source": [
    "electricity = pd.read_csv('data/electricity.csv', index_col = 0)\n",
    "data_formatter = ElectricityFormatter()\n",
    "train, valid, test = data_formatter.split_data(electricity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.629768Z",
     "start_time": "2020-03-12T22:46:11.901769Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TFTDataset(train)\n",
    "valid_dataset = TFTDataset(valid)\n",
    "test_dataset = TFTDataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.696618Z",
     "start_time": "2020-03-12T22:46:17.632194Z"
    },
    "code_folding": [
     1,
     97,
     113,
     133,
     143,
     152,
     173,
     187,
     195,
     201,
     206,
     216,
     225,
     229,
     241,
     300,
     443,
     446,
     461,
     472,
     477,
     485,
     491,
     497,
     520,
     525,
     529,
     533
    ]
   },
   "outputs": [],
   "source": [
    "class TemporalFusionTransformer(pl.LightningModule):\n",
    "    def __init__(self, params):\n",
    "        super(TemporalFusionTransformer, self).__init__()\n",
    "        \n",
    "        self.hparams = params\n",
    "        \n",
    "        self.name = self.__class__.__name__\n",
    "\n",
    "        # Data parameters\n",
    "        self.time_steps = int(params.total_time_steps)#int(params['total_time_steps'])\n",
    "        self.input_size = int(params.input_size)#int(params['input_size'])\n",
    "        self.output_size = int(params.output_size)#int(params['output_size'])\n",
    "        self.category_counts = json.loads(str(params.category_counts))#json.loads(str(params['category_counts']))\n",
    "        self.num_categorical_variables = len(self.category_counts)\n",
    "        self.num_regular_variables = self.input_size - self.num_categorical_variables\n",
    "        self.n_multiprocessing_workers = int(params.multiprocessing_workers) #int(params['multiprocessing_workers'])\n",
    "\n",
    "        # Relevant indices for TFT\n",
    "        self._input_obs_loc = json.loads(str(params.input_obs_loc))#json.loads(str(params['input_obs_loc']))\n",
    "        self._static_input_loc = json.loads(str(params.static_input_loc))#json.loads(str(params['static_input_loc']))\n",
    "        self._known_regular_input_idx = json.loads(str(params.known_regular_inputs))#json.loads(str(params['known_regular_inputs']))\n",
    "        self._known_categorical_input_idx = json.loads(str(params.known_categorical_inputs))#json.loads(str(params['known_categorical_inputs']))\n",
    "        \n",
    "        self.num_non_static_historical_inputs = self.get_historical_num_inputs()\n",
    "        self.num_non_static_future_inputs = self.get_future_num_inputs()\n",
    "        \n",
    "        self.column_definition = [\n",
    "                                  ('id', DataTypes.REAL_VALUED, InputTypes.ID),\n",
    "                                  ('hours_from_start', DataTypes.REAL_VALUED, InputTypes.TIME),\n",
    "                                  ('power_usage', DataTypes.REAL_VALUED, InputTypes.TARGET),\n",
    "                                  ('hour', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "                                  ('day_of_week', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "                                  ('hours_from_start', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "                                  ('categorical_id', DataTypes.CATEGORICAL, InputTypes.STATIC_INPUT),\n",
    "                                ]\n",
    "\n",
    "        # Network params\n",
    "        self.quantiles = [0.1, 0.5, 0.9]\n",
    "#         self.use_cudnn = use_cudnn  # Whether to use GPU optimised LSTM\n",
    "        self.hidden_layer_size = int(params.hidden_layer_size)#int(params['hidden_layer_size'])\n",
    "        self.dropout_rate = float(params.dropout_rate)#float(params['dropout_rate'])\n",
    "        self.max_gradient_norm = float(params.max_gradient_norm)#float(params['max_gradient_norm'])\n",
    "        self.learning_rate = float(params.learning_rate)#float(params['learning_rate'])\n",
    "        self.minibatch_size = int(params.minibatch_size)#int(params['minibatch_size'])\n",
    "        self.num_epochs = int(params.num_epochs)#int(params['num_epochs'])\n",
    "        self.early_stopping_patience = int(params.early_stopping_patience)#int(params['early_stopping_patience'])\n",
    "\n",
    "        self.num_encoder_steps = int(params.num_encoder_steps)#int(params['num_encoder_steps'])\n",
    "        self.num_stacks = int(params.stack_size)#int(params['stack_size'])\n",
    "        self.num_heads = int(params.num_heads)#int(params['num_heads'])\n",
    "\n",
    "        # Serialisation options\n",
    "#         self._temp_folder = os.path.join(params['model_folder'], 'tmp')\n",
    "#         self.reset_temp_folder()\n",
    "\n",
    "        # Extra components to store Tensorflow nodes for attention computations\n",
    "        self._input_placeholder = None\n",
    "        self._attention_components = None\n",
    "        self._prediction_parts = None\n",
    "\n",
    "        print('*** {} params ***'.format(self.name))\n",
    "        for k in vars(hparams):\n",
    "            print('# {} = {}'.format(k, vars(hparams)[k]))\n",
    "            \n",
    "        self.criterion = QuantileLossCalculator(self.quantiles, self.output_size)\n",
    "\n",
    "        # Build model\n",
    "        ## Build embeddings\n",
    "        self.build_embeddings()\n",
    "        \n",
    "        ## Build Static Contex Networks\n",
    "        self.build_static_context_networks()\n",
    "        \n",
    "        ## Building Variable Selection Networks\n",
    "        self.build_variable_selection_networks()\n",
    "        \n",
    "        ## Build Lstm\n",
    "        self.build_lstm()\n",
    "        \n",
    "        ## Build GLU for after lstm encoder decoder and layernorm\n",
    "        self.build_post_lstm_gate_add_norm()\n",
    "        \n",
    "        ## Build Static Enrichment Layer\n",
    "        self.build_static_enrichment()\n",
    "        \n",
    "        ## Building decoder multihead attention\n",
    "        self.build_temporal_self_attention()\n",
    "        \n",
    "        ## Building positionwise decoder\n",
    "        self.build_position_wise_feed_forward()\n",
    "        \n",
    "        ## Build output feed forward\n",
    "        self.build_output_feed_forward()\n",
    "        \n",
    "        ## Initializing remaining weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for name, p in self.named_parameters():\n",
    "            if ('lstm' in name and 'ih' in name) and 'bias' not in name:\n",
    "                #print(name)\n",
    "                #print(p.shape)\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "#                 torch.nn.init.kaiming_normal_(p, a=0, mode='fan_in', nonlinearity='sigmoid')\n",
    "            elif ('lstm' in name and 'hh' in name) and 'bias' not in name:\n",
    "        \n",
    "                 torch.nn.init.orthogonal_(p)\n",
    "            \n",
    "            elif 'lstm' in name and 'bias' in name:\n",
    "                #print(name)\n",
    "                #print(p.shape)\n",
    "                torch.nn.init.zeros_(p)\n",
    "        \n",
    "    def get_historical_num_inputs(self):\n",
    "        \n",
    "        obs_inputs = [i for i in self._input_obs_loc]\n",
    "        \n",
    "        known_regular_inputs = [i for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "            \n",
    "        known_categorical_inputs = [i for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "        \n",
    "        wired_embeddings = [i for i in range(self.num_categorical_variables)\n",
    "                            if i not in self._known_categorical_input_idx \n",
    "                            and i not in self._input_obs_loc]\n",
    "\n",
    "        unknown_inputs = [i for i in range(self.num_regular_variables)\n",
    "                          if i not in self._known_regular_input_idx\n",
    "                          and i not in self._input_obs_loc]\n",
    "\n",
    "        return len(obs_inputs+known_regular_inputs+known_categorical_inputs+wired_embeddings+unknown_inputs)\n",
    "    \n",
    "    def get_future_num_inputs(self):\n",
    "            \n",
    "        known_regular_inputs = [i for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "            \n",
    "        known_categorical_inputs = [i for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "\n",
    "        return len(known_regular_inputs + known_categorical_inputs)\n",
    "    \n",
    "    def build_embeddings(self):\n",
    "        self.categorical_var_embeddings = nn.ModuleList([nn.Embedding(self.category_counts[i], \n",
    "                                                                      self.hidden_layer_size) \n",
    "                                                     for i in range(self.num_categorical_variables)])\n",
    "\n",
    "        self.regular_var_embeddings = nn.ModuleList([nn.Linear(1, \n",
    "                                                              self.hidden_layer_size) \n",
    "                                                  for i in range(self.num_regular_variables)])\n",
    "\n",
    "    def build_variable_selection_networks(self):\n",
    "        \n",
    "        self.static_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                   input_size = self.hidden_layer_size * len(self._static_input_loc),\n",
    "                                                   output_size = len(self._static_input_loc),\n",
    "                                                   dropout_rate = self.dropout_rate)\n",
    "        \n",
    "        self.temporal_historical_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                                input_size = self.hidden_layer_size *\n",
    "                                                                        self.num_non_static_historical_inputs,\n",
    "                                                                output_size = self.num_non_static_historical_inputs,\n",
    "                                                                dropout_rate = self.dropout_rate,\n",
    "                                                                additional_context=self.hidden_layer_size)\n",
    "        \n",
    "        self.temporal_future_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                            input_size = self.hidden_layer_size *\n",
    "                                                                        self.num_non_static_future_inputs,\n",
    "                                                            output_size = self.num_non_static_future_inputs,\n",
    "                                                            dropout_rate = self.dropout_rate,\n",
    "                                                            additional_context=self.hidden_layer_size)\n",
    "        \n",
    "    def build_static_context_networks(self):\n",
    "        \n",
    "        self.static_context_variable_selection_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                                          dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        self.static_context_enrichment_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                              dropout_rate=self.dropout_rate)\n",
    "\n",
    "        self.static_context_state_h_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                           dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        self.static_context_state_c_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                           dropout_rate=self.dropout_rate)\n",
    "        \n",
    "    def build_lstm(self):\n",
    "        self.historical_lstm = nn.LSTM(input_size = self.hidden_layer_size,\n",
    "                                       hidden_size = self.hidden_layer_size,\n",
    "                                       batch_first = True)\n",
    "        self.future_lstm = nn.LSTM(input_size = self.hidden_layer_size,\n",
    "                                   hidden_size = self.hidden_layer_size,\n",
    "                                   batch_first = True)\n",
    "        \n",
    "    def build_post_lstm_gate_add_norm(self):\n",
    "        self.post_seq_encoder_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                                 self.hidden_layer_size,\n",
    "                                                                 self.dropout_rate,\n",
    "                                                                 activation = None)\n",
    "        \n",
    "    def build_static_enrichment(self):\n",
    "        self.static_enrichment = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                      dropout_rate = self.dropout_rate,\n",
    "                                                      additional_context=self.hidden_layer_size)\n",
    "        \n",
    "    def build_temporal_self_attention(self):\n",
    "        self.self_attn_layer = InterpretableMultiHeadAttention(n_head = self.num_heads, \n",
    "                                                               d_model = self.hidden_layer_size,\n",
    "                                                               dropout = self.dropout_rate)\n",
    "        \n",
    "        self.post_attn_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                           self.hidden_layer_size,\n",
    "                                                           self.dropout_rate,\n",
    "                                                           activation = None)\n",
    "        \n",
    "    def build_position_wise_feed_forward(self):\n",
    "        self.GRN_positionwise = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                     dropout_rate = self.dropout_rate)\n",
    "        \n",
    "        self.post_tfd_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                         self.hidden_layer_size,\n",
    "                                                         self.dropout_rate,\n",
    "                                                         activation = None)\n",
    "        \n",
    "    def build_output_feed_forward(self):\n",
    "        self.output_feed_forward = torch.nn.Linear(self.hidden_layer_size, \n",
    "                                                   self.output_size * len(self.quantiles))\n",
    "         \n",
    "    def get_decoder_mask(self, self_attn_inputs):\n",
    "        \"\"\"Returns causal mask to apply for self-attention layer.\n",
    "        Args:\n",
    "        self_attn_inputs: Inputs to self attention layer to determine mask shape\n",
    "        \"\"\"\n",
    "        len_s = self_attn_inputs.shape[1]\n",
    "        bs = self_attn_inputs.shape[0]\n",
    "        mask = torch.cumsum(torch.eye(len_s), 0)\n",
    "        mask = mask.repeat(bs,1,1).to(torch.float32)\n",
    "\n",
    "        return mask.to(DEVICE)\n",
    "    \n",
    "    def get_tft_embeddings(self, regular_inputs, categorical_inputs):\n",
    "        # Static input\n",
    "        if self._static_input_loc:\n",
    "            static_regular_inputs = [self.regular_var_embeddings[i](regular_inputs[:, 0, i:i + 1]) \n",
    "                                    for i in range(self.num_regular_variables)\n",
    "                                    if i in self._static_input_loc]\n",
    "            #print('static_regular_inputs')\n",
    "            #print([print(emb.shape) for emb in static_regular_inputs])\n",
    "            \n",
    "            static_categorical_inputs = [self.categorical_var_embeddings[i](categorical_inputs[Ellipsis, i])[:,0,:] \n",
    "                                         for i in range(self.num_categorical_variables)\n",
    "                                         if i + self.num_regular_variables in self._static_input_loc]\n",
    "            #print('static_categorical_inputs')\n",
    "            #print([print(emb.shape) for emb in static_categorical_inputs])\n",
    "            static_inputs = torch.stack(static_regular_inputs + static_categorical_inputs, axis = 1)\n",
    "        else:\n",
    "            static_inputs = None\n",
    "            \n",
    "        # Target input\n",
    "        obs_inputs = torch.stack([self.regular_var_embeddings[i](regular_inputs[Ellipsis, i:i + 1])\n",
    "                                     for i in self._input_obs_loc], axis=-1)\n",
    "        \n",
    "        # Observed (a prioir unknown) inputs\n",
    "        wired_embeddings = []\n",
    "        for i in range(self.num_categorical_variables):\n",
    "            if i not in self._known_categorical_input_idx \\\n",
    "            and i not in self._input_obs_loc:\n",
    "                e = self.categorical_var_embeddings[i](categorical_inputs[:, :, i])\n",
    "                wired_embeddings.append(e)\n",
    "\n",
    "        unknown_inputs = []\n",
    "        for i in range(self.num_regular_variables):\n",
    "            if i not in self._known_regular_input_idx \\\n",
    "            and i not in self._input_obs_loc:\n",
    "                e = self.regular_var_embeddings[i](regular_inputs[Ellipsis, i:i + 1])\n",
    "                unknown_inputs.append(e)\n",
    "                \n",
    "        if unknown_inputs + wired_embeddings:\n",
    "            unknown_inputs = torch.stack(unknown_inputs + wired_embeddings, axis=-1)\n",
    "        else:\n",
    "            unknown_inputs = None\n",
    "            \n",
    "        # A priori known inputs\n",
    "        known_regular_inputs = [self.regular_var_embeddings[i](regular_inputs[Ellipsis, i:i + 1])\n",
    "                                for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "        #print('known_regular_inputs')\n",
    "        #print([print(emb.shape) for emb in known_regular_inputs])\n",
    "        \n",
    "        known_categorical_inputs = [self.categorical_var_embeddings[i](categorical_inputs[Ellipsis, i])\n",
    "                                    for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "       #print('known_categorical_inputs')\n",
    "       #print([print(emb.shape) for emb in known_categorical_inputs])\n",
    "\n",
    "        known_combined_layer = torch.stack(known_regular_inputs + known_categorical_inputs, axis=-1)\n",
    "        \n",
    "        return unknown_inputs, known_combined_layer, obs_inputs, static_inputs\n",
    "        \n",
    "    def forward(self, all_inputs):\n",
    "\n",
    "        regular_inputs = all_inputs[:, :, :self.num_regular_variables].to(torch.float)\n",
    "        #print('regular_inputs')\n",
    "        #print(regular_inputs.shape)\n",
    "        categorical_inputs = all_inputs[:, :, self.num_regular_variables:].to(torch.long)\n",
    "        #print('categorical_inputs')\n",
    "        #print(categorical_inputs.shape)\n",
    "        \n",
    "        unknown_inputs, known_combined_layer, obs_inputs, static_inputs \\\n",
    "            = self.get_tft_embeddings(regular_inputs, categorical_inputs)\n",
    "        \n",
    "        # Isolate known and observed historical inputs.\n",
    "        if unknown_inputs is not None:\n",
    "              historical_inputs = torch.cat([\n",
    "                  unknown_inputs[:, :self.num_encoder_steps, :],\n",
    "                  known_combined_layer[:, :self.num_encoder_steps, :],\n",
    "                  obs_inputs[:, :self.num_encoder_steps, :]\n",
    "              ], axis=-1)\n",
    "        else:\n",
    "              historical_inputs = torch.cat([\n",
    "                  known_combined_layer[:, :self.num_encoder_steps, :],\n",
    "                  obs_inputs[:, :self.num_encoder_steps, :]\n",
    "              ], axis=-1)\n",
    "                \n",
    "        #print('historical_inputs')\n",
    "        #print(historical_inputs.shape)\n",
    "        \n",
    "        # Isolate only known future inputs.\n",
    "        future_inputs = known_combined_layer[:, self.num_encoder_steps:, :]\n",
    "        #print('future_inputs')\n",
    "        #print(future_inputs.shape)\n",
    "              \n",
    "        #print('static_inputs')\n",
    "        #print(static_inputs.shape)\n",
    "        \n",
    "        static_encoder, sparse_weights = self.static_vsn(static_inputs)\n",
    "        \n",
    "        #print('static_encoder')\n",
    "        #print(static_encoder.shape)\n",
    "        \n",
    "        #print('sparse_weights')\n",
    "        #print(sparse_weights.shape)\n",
    "        \n",
    "        static_context_variable_selection = self.static_context_variable_selection_grn(static_encoder)\n",
    "        #print('static_context_variable_selection')\n",
    "        #print(static_context_variable_selection.shape)\n",
    "        static_context_enrichment = self.static_context_enrichment_grn(static_encoder)\n",
    "        #print('static_context_enrichment')\n",
    "        #print(static_context_enrichment.shape)\n",
    "        static_context_state_h = self.static_context_state_h_grn(static_encoder)\n",
    "        #print('static_context_state_h')\n",
    "        #print(static_context_state_h.shape)\n",
    "        static_context_state_c = self.static_context_state_c_grn(static_encoder)\n",
    "        #print('static_context_state_c')\n",
    "        #print(static_context_state_c.shape)\n",
    "        \n",
    "        historical_features, historical_flags \\\n",
    "        = self.temporal_historical_vsn((historical_inputs,\n",
    "                                        static_context_variable_selection))\n",
    "        #print('historical_features')\n",
    "        #print(historical_features.shape)\n",
    "        #print('historical_flags')\n",
    "        #print(historical_flags.shape)\n",
    "        \n",
    "        future_features, future_flags \\\n",
    "        = self.temporal_future_vsn((future_inputs,\n",
    "                                    static_context_variable_selection))\n",
    "        #print('future_features')\n",
    "        #print(future_features.shape)\n",
    "        #print('future_flags')\n",
    "        #print(future_flags.shape)\n",
    "        \n",
    "        history_lstm, (state_h, state_c) \\\n",
    "        = self.historical_lstm(historical_features,\n",
    "                               (static_context_state_h.unsqueeze(0),\n",
    "                                static_context_state_c.unsqueeze(0)))\n",
    "        #print('history_lstm')\n",
    "        #print(history_lstm.shape)\n",
    "        #print('state_h')\n",
    "        #print(state_h.shape)\n",
    "        #print('state_c')\n",
    "        #print(state_c.shape)\n",
    "        \n",
    "        future_lstm, _ = self.future_lstm(future_features,\n",
    "                                          (state_h,\n",
    "                                           state_c))\n",
    "        #print('future_lstm')\n",
    "        #print(future_lstm.shape)\n",
    "        \n",
    "        # Apply gated skip connection\n",
    "        input_embeddings = torch.cat((historical_features, future_features), axis=1)\n",
    "        #print('input_embeddings')\n",
    "        #print(input_embeddings.shape) \n",
    "        \n",
    "        lstm_layer = torch.cat((history_lstm, future_lstm), axis=1)\n",
    "        #print('lstm_layer')\n",
    "        #print(lstm_layer.shape) \n",
    "        \n",
    "        temporal_feature_layer = self.post_seq_encoder_gate_add_norm(lstm_layer, input_embeddings)\n",
    "        #print('temporal_feature_layer')\n",
    "        #print(temporal_feature_layer.shape)  \n",
    "        \n",
    "        # Static enrichment layers\n",
    "        expanded_static_context = static_context_enrichment.unsqueeze(1)\n",
    "        \n",
    "        enriched = self.static_enrichment((temporal_feature_layer, expanded_static_context))\n",
    "        #print('enriched')\n",
    "        #print(enriched.shape)    \n",
    "        \n",
    "        # Decoder self attention\n",
    "        #self.mask = self.get_decoder_mask(enriched)\n",
    "        x, self_att = self.self_attn_layer(enriched, \n",
    "                                           enriched, \n",
    "                                           enriched,\n",
    "                                           mask = self.get_decoder_mask(enriched))\n",
    "        #print('x')\n",
    "        #print(x.shape)\n",
    "        #print('self_att')\n",
    "        #print(self_att.shape)\n",
    "        \n",
    "        x = self.post_attn_gate_add_norm(x, enriched)\n",
    "        #print('x')\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # Nonlinear processing on outputs\n",
    "        decoder = self.GRN_positionwise(x)\n",
    "        #print('decoder')\n",
    "        #print(decoder.shape)\n",
    "        \n",
    "        # Final skip connection\n",
    "        transformer_layer = self.post_tfd_gate_add_norm(decoder, temporal_feature_layer)\n",
    "        #print('transformer_layer')\n",
    "        #print(transformer_layer.shape)\n",
    "        \n",
    "        outputs = self.output_feed_forward(transformer_layer[Ellipsis, self.num_encoder_steps:, :])\n",
    "        #print('outputs')\n",
    "        #print(outputs.shape)\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return self.criterion.apply(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y, _ = batch\n",
    "        \n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.float)\n",
    "#         print('y')\n",
    "#         print(y.shape)\n",
    "        y_hat = self.forward(x)\n",
    "#         print('y_hat')\n",
    "#         print(y_hat.shape)\n",
    "        loss = self.loss(y_hat, torch.cat([y, y, y], dim = -1))\n",
    "        #print(loss.shape)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y, _ = batch\n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.float)\n",
    "        y_hat = self.forward(x)\n",
    "        #print(y_hat.shape)\n",
    "        #print(torch.cat([y, y, y], dim = -1).shape)\n",
    "        loss = self.loss(y_hat, torch.cat([y, y, y], dim = -1))\n",
    "        #print(loss)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # OPTIONAL\n",
    "        x, y, _ = batch\n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.float)\n",
    "        y_hat = self.forward(x)\n",
    "        return {'test_loss': self.loss(y_hat, torch.cat([y, y, y], dim = -1))}\n",
    "\n",
    "    def test_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'test_loss': avg_loss}\n",
    "        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        # (LBFGS it is automatically supported, no need for closure function)\n",
    "        return [torch.optim.Adam(self.parameters(), lr=0.01)]#self.learning_rate)]\n",
    "    \n",
    "    def plot_grad_flow(self, named_parameters):\n",
    "        ave_grads = []\n",
    "        layers = []\n",
    "        for name, p in named_parameters:\n",
    "            if p.grad is not None:\n",
    "                if (p.requires_grad) and (\"bias\" not in name):\n",
    "                    layers.append(name)\n",
    "                    ave_grads.append(p.grad.abs().mean())\n",
    "                    self.logger.experiment.add_histogram(tag=name, values=p.grad,\n",
    "                                                         global_step=self.trainer.global_step)\n",
    "            else:\n",
    "                 print('{} - {}'.format(name, p.requires_grad))\n",
    "            \n",
    "        plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "        plt.hlines(0, 0, len(ave_grads), linewidth=1, color=\"k\" )\n",
    "        plt.xticks(list(range(0,len(ave_grads), 1)), layers, rotation='vertical')\n",
    "        plt.xlim(left=0, right=len(ave_grads))\n",
    "        plt.xlabel(\"Layers\")\n",
    "        plt.ylabel(\"average gradient\")\n",
    "        plt.title(\"Gradient flow\")\n",
    "        plt.grid(True)\n",
    "        plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "    \n",
    "    def on_after_backward(self):\n",
    "        # example to inspect gradient information in tensorboard\n",
    "        if self.trainer.global_step % 25 == 0:  \n",
    "            self.plot_grad_flow(self.named_parameters())\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(train_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(valid_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(test_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.761570Z",
     "start_time": "2020-03-12T22:46:17.698467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.766341Z",
     "start_time": "2020-03-12T22:46:17.763136Z"
    }
   },
   "outputs": [],
   "source": [
    "params = data_formatter.get_experiment_params()\n",
    "params.update(data_formatter.get_default_model_params())\n",
    "\n",
    "parser = ArgumentParser(add_help=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.772354Z",
     "start_time": "2020-03-12T22:46:17.767934Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in params:\n",
    "    if type(params[k]) in [int, float]:\n",
    "        parser.add_argument('--{}'.format(k), type=type(params[k]), default = params[k])\n",
    "    else:\n",
    "        parser.add_argument('--{}'.format(k), type=str, default = str(params[k]))\n",
    "hparams = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.880654Z",
     "start_time": "2020-03-12T22:46:17.774319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TemporalFusionTransformer params ***\n",
      "# total_time_steps = 192\n",
      "# num_encoder_steps = 168\n",
      "# num_epochs = 100\n",
      "# early_stopping_patience = 5\n",
      "# multiprocessing_workers = 5\n",
      "# column_definition = [('id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('hours_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('power_usage', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hours_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('categorical_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]\n",
      "# input_size = 5\n",
      "# output_size = 1\n",
      "# category_counts = [369]\n",
      "# input_obs_loc = [0]\n",
      "# static_input_loc = [4]\n",
      "# known_regular_inputs = [1, 2, 3]\n",
      "# known_categorical_inputs = [0]\n",
      "# dropout_rate = 0.1\n",
      "# hidden_layer_size = 160\n",
      "# learning_rate = 0.001\n",
      "# minibatch_size = 64\n",
      "# max_gradient_norm = 0.01\n",
      "# num_heads = 4\n",
      "# stack_size = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformer(\n",
       "  (categorical_var_embeddings): ModuleList(\n",
       "    (0): Embedding(369, 160)\n",
       "  )\n",
       "  (regular_var_embeddings): ModuleList(\n",
       "    (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "    (1): Linear(in_features=1, out_features=160, bias=True)\n",
       "    (2): Linear(in_features=1, out_features=160, bias=True)\n",
       "    (3): Linear(in_features=1, out_features=160, bias=True)\n",
       "  )\n",
       "  (static_context_variable_selection_grn): GatedResidualNetwork(\n",
       "    (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (glu_add_norm): GateAddNormNetwork(\n",
       "      (GLU): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_enrichment_grn): GatedResidualNetwork(\n",
       "    (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (glu_add_norm): GateAddNormNetwork(\n",
       "      (GLU): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_h_grn): GatedResidualNetwork(\n",
       "    (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (glu_add_norm): GateAddNormNetwork(\n",
       "      (GLU): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_c_grn): GatedResidualNetwork(\n",
       "    (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (glu_add_norm): GateAddNormNetwork(\n",
       "      (GLU): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_vsn): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (skip_linear): Linear(in_features=160, out_features=1, bias=True)\n",
       "      (glu_add_norm): GateAddNormNetwork(\n",
       "        (GLU): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (W4): Linear(in_features=160, out_features=1, bias=True)\n",
       "          (W5): Linear(in_features=160, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "        (LayerNorm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (per_feature_grn): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_historical_vsn): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (W2): Linear(in_features=640, out_features=160, bias=True)\n",
       "      (W3): Linear(in_features=160, out_features=160, bias=False)\n",
       "      (skip_linear): Linear(in_features=640, out_features=4, bias=True)\n",
       "      (glu_add_norm): GateAddNormNetwork(\n",
       "        (GLU): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (W4): Linear(in_features=160, out_features=4, bias=True)\n",
       "          (W5): Linear(in_features=160, out_features=4, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "        (LayerNorm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (per_feature_grn): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_future_vsn): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (W2): Linear(in_features=480, out_features=160, bias=True)\n",
       "      (W3): Linear(in_features=160, out_features=160, bias=False)\n",
       "      (skip_linear): Linear(in_features=480, out_features=3, bias=True)\n",
       "      (glu_add_norm): GateAddNormNetwork(\n",
       "        (GLU): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (W4): Linear(in_features=160, out_features=3, bias=True)\n",
       "          (W5): Linear(in_features=160, out_features=3, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "        (LayerNorm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (per_feature_grn): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): GatedResidualNetwork(\n",
       "        (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (glu_add_norm): GateAddNormNetwork(\n",
       "          (GLU): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "            (activation): Sigmoid()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (historical_lstm): LSTM(160, 160, batch_first=True)\n",
       "  (future_lstm): LSTM(160, 160, batch_first=True)\n",
       "  (post_seq_encoder_gate_add_norm): GateAddNormNetwork(\n",
       "    (GLU): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (static_enrichment): GatedResidualNetwork(\n",
       "    (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W3): Linear(in_features=160, out_features=160, bias=False)\n",
       "    (glu_add_norm): GateAddNormNetwork(\n",
       "      (GLU): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (self_attn_layer): InterpretableMultiHeadAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (v_layer): Linear(in_features=160, out_features=40, bias=False)\n",
       "    (q_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (k_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (v_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (softmax): Softmax(dim=2)\n",
       "    )\n",
       "    (w_h): Linear(in_features=40, out_features=160, bias=False)\n",
       "  )\n",
       "  (post_attn_gate_add_norm): GateAddNormNetwork(\n",
       "    (GLU): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (GRN_positionwise): GatedResidualNetwork(\n",
       "    (W1): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (W2): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (glu_add_norm): GateAddNormNetwork(\n",
       "      (GLU): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "      (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (post_tfd_gate_add_norm): GateAddNormNetwork(\n",
       "    (GLU): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (W4): Linear(in_features=160, out_features=160, bias=True)\n",
       "      (W5): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (LayerNorm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_feed_forward): Linear(in_features=160, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tft = TemporalFusionTransformer(hparams)#.to(DEVICE)\n",
    "tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:46:17.886155Z",
     "start_time": "2020-03-12T22:46:17.882969Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor = 'val_loss',\n",
    "                                    min_delta = 1e-4,\n",
    "                                    patience = tft.early_stopping_patience,\n",
    "                                    verbose=False,\n",
    "                                    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:46:08.138Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33e81f2bb9b416ca4db3609292c9b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=20.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=20.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=20.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_nb_epochs = tft.num_epochs,\n",
    "                     gpus = 1, \n",
    "                     track_grad_norm = 2, \n",
    "                     gradient_clip_val = tft.max_gradient_norm,\n",
    "                     early_stop_callback = early_stop_callback,\n",
    "#                      train_percent_check = 1,\n",
    "                     overfit_pct=0.01,\n",
    "                     #fast_dev_run=True,\n",
    "                     profiler=True,\n",
    "                     print_nan_grads = True,\n",
    "                     #distributed_backend='dp'\n",
    "                    )    \n",
    "trainer.fit(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
